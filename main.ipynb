{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.extract import ExtractFeatures\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "webshell_data = []\n",
    "benign_data = []\n",
    "\n",
    "webshells = os.listdir(os.path.curdir + '/data/webshells')\n",
    "random.shuffle(webshells)\n",
    "\n",
    "benigns = os.listdir(os.path.curdir + '/data/benigns')\n",
    "random.shuffle(benigns)\n",
    "\n",
    "webshellsLongest = []\n",
    "benignsLongest = []\n",
    "webshellsEntropy = []\n",
    "benignsEntropy = []\n",
    "\n",
    "for file in webshells[0:260]:\n",
    "    extractor = ExtractFeatures('/data/webshells/'+file, 'dataset.csv')\n",
    "    result = extractor.extract_function_names()\n",
    "    webshellsLongest.append({ 'class': 'malware', 'longest': extractor.extract_longest_string()})\n",
    "    webshellsEntropy.append({ 'class': 'malware', 'entropy': extractor.extract_entropy_file()})\n",
    "    result['class'] = 'malware'\n",
    "    webshell_data.append(result)\n",
    "  \n",
    "for file in benigns[0:260]:\n",
    "    extractor = ExtractFeatures('/data/benigns/'+file, 'dataset.csv')\n",
    "    result = extractor.extract_function_names()\n",
    "    benignsLongest.append({ 'class': 'benign', 'longest': extractor.extract_longest_string()})\n",
    "    benignsEntropy.append({ 'class': 'benign', 'entropy': extractor.extract_entropy_file()})\n",
    "    result['class'] = 'benign'\n",
    "    benign_data.append(result)\n",
    "\n",
    "df_webshell = pd.DataFrame(webshell_data).fillna(0)\n",
    "df_benigns = pd.DataFrame(benign_data).fillna(0)\n",
    "\n",
    "abc = pd.concat([df_webshell, df_benigns]).fillna(0)\n",
    "# abc.set_index('class').to_csv('dataset.csv')\n",
    "\n",
    "# df_bengin_longest = pd.DataFrame(webshellsLongest + benignsLongest)\n",
    "# dataset = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_bengin_longest = pd.DataFrame(benignsLongest)\n",
    "df_bengin_longest = df_bengin_longest.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_malware_longest = pd.DataFrame(webshellsLongest)\n",
    "df_malware_longest = df_malware_longest.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_malware_entropy = pd.DataFrame(webshellsEntropy)\n",
    "df_malware_entropy = df_malware_entropy.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_2 = pd.DataFrame(webshellsEntropy + benignsEntropy)\n",
    "dataset_2 = df_2.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           longest\n",
      "count   260.000000\n",
      "mean    200.938462\n",
      "std     390.920896\n",
      "min      37.000000\n",
      "25%     113.000000\n",
      "50%     149.500000\n",
      "75%     207.250000\n",
      "max    6282.000000\n",
      "             longest\n",
      "count     260.000000\n",
      "mean    15837.053846\n",
      "std     43557.291466\n",
      "min        19.000000\n",
      "25%        93.750000\n",
      "50%       194.000000\n",
      "75%      2612.000000\n",
      "max    398410.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_bengin_longest.set_index('class').describe())\n",
    "print(df_malware_longest.set_index('class').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_webshell = pd.DataFrame(webshellsLongest)\n",
    "df_benign = pd.DataFrame(benignsLongest)\n",
    "\n",
    "plt.plot(df_webshell['longest'], c='red')\n",
    "plt.plot(df_benign['longest'])\n",
    "\n",
    "plt.legend([\"malware\", \"benign\"], loc =\"right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df_webshell_entropy = pd.DataFrame(webshellsEntropy)\n",
    "df_benign_entropy = pd.DataFrame(benignsEntropy)\n",
    "\n",
    "\n",
    "print (\"Avergate of Webshell %f and Benign is %f\" % (df_webshell_entropy['entropy'].mean(), df_benign_entropy['entropy'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_webshell = pd.DataFrame(webshellsEntropy)\n",
    "df_benign = pd.DataFrame(benignsEntropy)\n",
    "\n",
    "xpoints = np.array(df_benign.index.array)\n",
    "ypoints = np.array(df_benign['entropy'])\n",
    "\n",
    "plt.scatter(xpoints, ypoints)\n",
    "\n",
    "xpoints = np.array(df_webshell.index.array)\n",
    "ypoints = np.array(df_webshell['entropy'])\n",
    "\n",
    "plt.scatter(xpoints, ypoints, c='red')\n",
    "plt.legend(['benign', 'malware'])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.extract import ExtractFeatures\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "file = '5284c689364b3d94f6abf428e87b35c6.php'\n",
    "extractor = ExtractFeatures('/data/webshells/'+file, 'dataset_test.csv')\n",
    "extractor.extract_longest_string()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('./dataset.csv')\n",
    "X = df.drop(columns=['class', 'no']).to_numpy()\n",
    "Y = df['class'].to_numpy()\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "scaled_df = std_scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "new_X = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "# for label in set(Y):\n",
    "#     X_class = new_X[Y == label]\n",
    "#     plt.scatter(X_class[:, 0], X_class[:, 1], label=label)\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "# plt.bar(\n",
    "#     range(1,len(pca.explained_variance_)+1),\n",
    "#     pca.explained_variance_\n",
    "#     )\n",
    " \n",
    " \n",
    "# plt.xlabel('PCA Feature')\n",
    "# plt.ylabel('Explained variance')\n",
    "# plt.title('Feature Explained Variance')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# pca_features = pca.fit_transform(scaled_df)\n",
    "\n",
    "# pca_df = pd.DataFrame(data=pca_features)\n",
    "# pca_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df = pd.read_csv('./dataset.csv')\n",
    "features = df.drop(columns=['no', 'class']).columns\n",
    "df['class'] = le.fit_transform(df['class'])\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(df[features[0:5]])\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "}\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    labels=labels,\n",
    "    dimensions=range(5),\n",
    "    color=df[\"class\"]\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = px.data.iris()\n",
    "features = [\"sepal_width\", \"sepal_length\", \"petal_width\", \"petal_length\"]\n",
    "\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(df[features])\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "}\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    labels=labels,\n",
    "    dimensions=range(4),\n",
    "    color=df[\"species\"]\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df = pd.read_csv('./dataset.csv')\n",
    "\n",
    "target = le.fit_transform(df['class'])\n",
    "train = df.drop(columns=['no', 'class']).values\n",
    "\n",
    "X_std = StandardScaler().fit_transform(train)\n",
    "# Calculating Eigenvectors and eigenvalues of Cov matirx\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "# Create a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [ (np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the eigenvalue, eigenvector pair from high to low\n",
    "eig_pairs.sort(key = lambda x: x[0], reverse= True)\n",
    "\n",
    "# Calculation of Explained Variance from the eigenvalues\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)] # Individual explained variance\n",
    "cum_var_exp = np.cumsum(var_exp) # Cumulative explained variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "[ n for n,i in enumerate(cum_var_exp) if i>90 ][0]\n",
    "\n",
    "pca = PCA(n_components=274)\n",
    "pca.fit(X_std)\n",
    "X_228d = pca.transform(X_std)\n",
    "X_228d.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
